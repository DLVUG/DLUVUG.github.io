import{_ as e,o as r,c as t,a as i}from"./app.04b35b91.js";const g=JSON.parse('{"title":"ViT","description":"ViT","frontmatter":{"title":"ViT","description":"ViT","date":"2022-07-05T00:00:00.000Z","tags":["谢彧","ALL"]},"headers":[{"level":2,"title":"一、整体架构","slug":"一、整体架构","link":"#一、整体架构","children":[{"level":3,"title":"1、论文版本","slug":"_1、论文版本","link":"#_1、论文版本","children":[]},{"level":3,"title":"2、详细版本","slug":"_2、详细版本","link":"#_2、详细版本","children":[]}]}],"relativePath":"doc/ViT.md"}'),a={name:"doc/ViT.md"},s=i('<h1 id="vit" tabindex="-1">ViT <a class="header-anchor" href="#vit" aria-hidden="true">#</a></h1><h2 id="一、整体架构" tabindex="-1">一、整体架构 <a class="header-anchor" href="#一、整体架构" aria-hidden="true">#</a></h2><h3 id="_1、论文版本" tabindex="-1">1、论文版本 <a class="header-anchor" href="#_1、论文版本" aria-hidden="true">#</a></h3><p><img src="https://img-blog.csdnimg.cn/20210626105321101.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTQxMDk3,size_16,color_FFFFFF,t_70#pic_center" alt="img"></p><h3 id="_2、详细版本" tabindex="-1">2、详细版本 <a class="header-anchor" href="#_2、详细版本" aria-hidden="true">#</a></h3><img src="https://img-blog.csdnimg.cn/20210704124600507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTQxMDk3,size_16,color_FFFFFF,t_70#pic_center" alt="img"><p>背景：</p><p>所以这篇文章提出来的背景是，看到了transformer在NLP领域中，随着model变复杂，以及数据集的增大，模型性能仍然未达到饱和。想把transformer用在视觉领域。</p><p>实验：</p><p>证明效果比CNN好的过程： 在中小型数据集上训练，比如mid-size的imagenet,但是效果还是比resnet差几个百分点。</p><p>如果images 14M-300M, 发现VIT战胜了归纳偏置</p><p>当然，也举例了以往人做的实验， 有的结果不错，但是实现起来很复杂。 也有与他们工作很相似的，但是只能处理小分辨率，而作者可以处理中分辨率的图像</p><p><img src="" alt="1667522873787"></p><p><img src="" alt="1667523244451"></p><p>Figure 5: Performance versus pre-training compute for different architectures: Vision Transformers, ResNets, and hybrids. Vision Transformers generally outperform ResNets with the same computational budget. Hybrids improve upon pure Transformers for smaller model sizes, but the gap vanishes for larger models</p><p>conclusion: 既然vit在分类问题上做的效果很好，那么在这种分割，检测等领域是不是也有迹可循。为其提供了一种新的思路</p><p>code in github:</p><p><a href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_classification/vision_transformer" target="_blank" rel="noreferrer">https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_classification/vision_transformer</a></p>',18),n=[s];function o(c,p,d,l,m,_){return r(),t("div",null,n)}const f=e(a,[["render",o]]);export{g as __pageData,f as default};
