---
title: softmax回归
description: softmax回归
date: 2022-09-30
tags:
  - 张栋
  - ALL
---



# softmax回归

## 一、概念

Softmax回归(Softmax regression)，也称为多项（Multinomial)或多类（Multi-Class)的Logistic回归，是Logistic回归在多分类问题上的推广。

## 二、回归模型

Softmax回归跟线性回归一样将输入特征与权重做线性叠加。与线性回归的一个主要不同在于，Softmax回归的输出值个数等于标签里的类别数。比如一共有4种特征和3种输出动物类别(狗、猫、鸡），则权重包含12个标量（带下标的w ）、偏差包含3个标量（带下标的b ），且对每个输入计算o1,o2 ,o3的输出：

 ![image-20220928145718808]()

最后，再对这些输出值进行softmax函数运算。

![image-20220928145812103]()

图用神经网络图描绘了上面的计算。softmax回归同线性回归一样，也是一个单层神经网络。由于每个输出o1,o2,o3的计算都要依赖所有的输入x1,x2,x3,x4,所以softmax回归的输出层也是一个全连接层。

## 三、softmax函数

Softmax用于多分类过程中，它将多个神经元的输出(o1,o2,o3)映射到（0，1）区间内，可以看成概率来理解，从而来进行多分类。



![image-20220928150652285]()

softmax回归对样本i分类的矢量计算表达式为:

![image-20220928150844264]()

## 四、损失函数

交叉熵损失函数：

![img](https://img-blog.csdnimg.cn/20200908162036235.png)

f(zc)是 softmax函数的输出值。yc就是样本真值。l就是最终的损失函数值了。

![image-20220928152753837]()

![image-20220928152809118]()显然，与真值越接近，损失函数越小，与真值相去越远 ，损失函数越大。优化过程就是不断的将与真值接近的那个概率值提升，提升，再提升，让损失函数降低，降低，再降低。

## 五、优化算法

梯度下降：

![image-20220928153049930]()

## 六、模型预测与评价

预测：

在训练好softmax回归模型后，给定任一样本特征，就可以预测每个输出类别的概率。通常，我们把预测概率最大的类别作为输出类别。


评价：

如果它与真实类别（标签）一致，说明这次预测是正确的。一般使用准确率（accuracy）来评价模型的表现，它等于正确预测数量与总预测数量之比



